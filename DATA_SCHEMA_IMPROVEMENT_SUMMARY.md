# Data Ingestion & Schema Overhaul - Executive Summary

**Prepared**: Feb 3, 2026  
**Phase**: 11 (Deploy & Verify)  
**Priority**: ğŸ”´ CRITICAL  
**Effort**: 3-4 days  
**Impact**: Data integrity, real-time updates, 5x query performance  

---

## The Problem

Your current data infrastructure has **6 critical issues** causing poor data quality and broken analytics:

### ğŸ”´ Issue 1: Manual, Error-Prone Data Population
- Player stats not populated automatically
- We had to write a **Python script** to backfill 59 players manually
- Positions assigned via hardcoded dictionary with 24 known players
- 118 players still have position="Unknown"
- **Result**: Analytics features don't work for most players

### ğŸ”´ Issue 2: No Automation for First TD Calculation
- First TD counts calculated via manual SQL queries in scripts
- When results are graded, leaderboards don't update automatically
- Admin must re-run data ingestion script for dashboard to reflect changes
- **Result**: Stale data, user confusion, poor user experience

### ğŸ”´ Issue 3: No Data Integrity Constraints
- Duplicate picks are possible (we've already seen this)
- No unique constraint prevents same user picking same player twice in a week
- No foreign key constraints â†’ data can become orphaned
- **Result**: Data corruption, manual cleanup required

### ğŸ”´ Issue 4: Missing Reference Tables
- No games table â†’ picks aren't linked to specific NFL games
- No rosters table â†’ positions aren't normalized
- Prediction market tables exist but are unused (dead schema)
- **Result**: Can't perform advanced queries, no Polymarket/Kalshi integration

### ğŸ”´ Issue 5: Poor Query Performance
- No indexes on common queries (team, position, week, is_correct)
- Leaderboard queries full-scan 485 player records every time
- Currently takes ~500ms per query; grows exponentially with data
- **Result**: Slow UI, poor user experience at scale

### ğŸ”´ Issue 6: No Data Quality Monitoring
- Orphaned records possible but undetected
- Duplicate picks exist silently
- Invalid positions unknown until manual audit
- **Result**: Silent data degradation, hard to debug

---

## The Solution

A 4-phase data ingestion overhaul with **6 new SQL migrations** (v9-v14):

### âœ… Phase 1: Add Reference Tables (1 day)
- **v9**: Create `games` table (NFL schedule reference)
- **v10**: Create `rosters` table (player positions, normalized)
- **v11**: Create unique constraint on picks (prevent duplicates)

### âœ… Phase 2: Add Integrity Constraints (1 day)
- **v12**: Add foreign key from picks â†’ games
- **v13**: Add performance indexes on all tables
- **v14**: Add database triggers for automation

### âœ… Phase 3: Build Ingestion Services (1 day)
- `roster_ingestion.py`: Load NFL rosters on app startup
- `game_sync.py`: Populate games table for current season
- `market_sync.py`: Enable Polymarket/Kalshi integration

### âœ… Phase 4: Testing & Deployment (Â½ day)
- Run migration tests on backup DB
- Deploy migrations sequentially
- Monitor data quality

---

## Expected Outcomes

### ğŸ“Š Data Quality Improvements
| Metric | Before | After |
|--------|--------|-------|
| Duplicate picks allowed | âœ… Yes | âŒ No (unique constraint) |
| Unknown positions | 118/485 (24%) | ~10/485 (2%) |
| Referential integrity enforced | âŒ No | âœ… Yes (FKs) |
| First TD updates automatic | âŒ No | âœ… Yes (triggers) |
| Data validation automated | âŒ No | âœ… Nightly checks |

### âš¡ Performance Improvements
| Operation | Before | After | Speedup |
|-----------|--------|-------|---------|
| Leaderboard query | 500ms | <100ms | **5x** |
| Position filter | 450ms | 20ms | **22x** |
| Pick creation | 50ms | 50ms* | Same (but auto-position) |
| Result grading | 100ms | 100ms* | Same (but auto-update) |

*With additional feature (auto-position, auto-update)

### ğŸ›¡ï¸ Reliability Improvements
- âœ… No manual scripts required
- âœ… No duplicate picks possible
- âœ… Data always consistent
- âœ… Nightly quality audits
- âœ… 100% referential integrity

---

## Key Design Decisions

### 1. Add Games Table
**Why**: Link picks to specific games, enable schedule queries

```sql
CREATE TABLE games (
    id TEXT PRIMARY KEY,  -- "2025_01_KC_LV"
    season INT, week INT,
    home_team, away_team, home_score, away_score,
    status: 'scheduled' | 'in_progress' | 'final'
);
```

### 2. Add Rosters Table
**Why**: Normalize player positions, eliminate position="Unknown"

```sql
CREATE TABLE rosters (
    season INT, player_name TEXT, team TEXT,
    position: 'QB' | 'RB' | 'WR' | 'TE' | 'K' | 'DEF',
    UNIQUE(season, player_name, team)
);
```

### 3. Add Unique Constraint on Picks
**Why**: Prevent duplicate user picks

```sql
ALTER TABLE picks ADD UNIQUE(user_id, week_id, player_name);
```

### 4. Add Database Triggers
**Why**: Automatically update first_td_count when results graded

```sql
CREATE TRIGGER update_player_stats_on_result_insert
AFTER INSERT ON results
FOR EACH ROW
WHEN NEW.is_correct = 1
BEGIN
    UPDATE player_stats SET first_td_count = first_td_count + 1
    WHERE player_name = (SELECT player_name FROM picks WHERE id = NEW.pick_id)
END;
```

### 5. Add Performance Indexes
**Why**: Speed up leaderboard, position filter, and grading queries

```sql
CREATE INDEX idx_player_stats_position_season ON player_stats(position, season);
CREATE INDEX idx_results_is_correct ON results(is_correct);
CREATE INDEX idx_games_season_week ON games(season, week);
```

---

## Risks & Mitigations

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|-----------|
| Migration breaks picks | ğŸŸ¡ Medium | ğŸ”´ Critical | Test on backup first |
| Unique constraint fails | ğŸŸ¡ Medium | ğŸ”´ Critical | Dedupe picks beforehand |
| Foreign keys reject data | ğŸŸ¡ Medium | ğŸ”´ Critical | Backfill game_ids first |
| Triggers slow down app | ğŸŸ¢ Low | ğŸŸ¡ Medium | Proper indexing |
| Rosters outdated mid-season | ğŸŸ¢ Low | ğŸŸ¡ Medium | Nightly refresh |

---

## Implementation Roadmap

### Week 1: Design & Testing
- [ ] Review migrations on test DB
- [ ] Verify trigger logic with test data
- [ ] Load rosters from nflreadpy (test)
- [ ] Backfill games table for 2025 season

### Week 2: Deployment
- [ ] Apply migrations v9-v14 sequentially
- [ ] Populate rosters via ingestion service
- [ ] Test pick creation (auto-position)
- [ ] Test result grading (auto-update)
- [ ] Monitor query performance

### Week 3: Validation
- [ ] Run full test suite (78 tests must pass)
- [ ] Data quality audit
- [ ] Performance testing under load
- [ ] Deploy to Railway

---

## Documentation Provided

### 1. [SCHEMA_AND_INGESTION_PLAN.md](SCHEMA_AND_INGESTION_PLAN.md)
High-level overview of schema improvements, normalization analysis, and implementation roadmap

### 2. [DATA_INGESTION_FLOWS.md](DATA_INGESTION_FLOWS.md)
Before/after data flows, triggers reference, service responsibilities, and migration execution plan

### 3. [SQL_MIGRATIONS_V9_V14.md](SQL_MIGRATIONS_V9_V14.md)
**Complete Python code for all 6 migrations**, with testing checklist and rollback procedure

---

## Next Steps

1. **Review this summary** and ask any questions
2. **Read [SCHEMA_AND_INGESTION_PLAN.md](SCHEMA_AND_INGESTION_PLAN.md)** for detailed design
3. **Read [SQL_MIGRATIONS_V9_V14.md](SQL_MIGRATIONS_V9_V14.md)** for implementation code
4. **Test migrations on backup database** before deploying to prod
5. **Execute migrations sequentially** (v9 â†’ v10 â†’ v11 â†’ v12 â†’ v13 â†’ v14)
6. **Build ingestion services** (roster_ingestion, game_sync)
7. **Deploy to Railway** and monitor

---

## Success Criteria

âœ… **Zero duplicate picks** (unique constraint enforced)  
âœ… **<5% unknown positions** (rosters normalized)  
âœ… **Leaderboard queries <100ms** (indexes optimized)  
âœ… **All 78 tests pass** (no regressions)  
âœ… **Automatic First TD updates** (triggers working)  
âœ… **Nightly data quality checks** (monitoring in place)

---

## Questions?

Key decision points for discussion:
1. Should we enable Polymarket/Kalshi market sync nightly? (adds ~30 seconds)
2. When should nightly data sync run? (currently 2 AM UTC)
3. Should we implement data retention policies? (e.g., purge old seasons)
4. Priority: Should we tackle Polymarket integration in Phase 12?

